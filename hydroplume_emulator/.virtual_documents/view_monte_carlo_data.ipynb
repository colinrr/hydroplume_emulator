





# Imports
import pandas as pd
import numpy as np
# import scipy.io as spio
from os.path import join
from utils.mat_tools import matfile_struct_to_dict as mat2dict
import pprint
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
import seaborn as sns
import matplotlib.pyplot as plt








# ---- Directories and files ----
data_dir = 'data/'

monte_carlo_fixed_vars_file = join(data_dir, 'fixed_MC_vars.mat')  # Simulation fixed input parameters
monte_carlo_rand_vars_file  = join(data_dir, 'rand_MC_vars.parquet') # Simulation randomized input parameters
monte_carlo_data_file       = join(data_dir, 'KatlaHydro_v8_noLd_2024-06-30_N20000.parquet')  # I/O data table for main parameters of interest
monte_carlo_scaled_file       = join(data_dir, 'KatlaHydro_v8_noLd_2024-06-30_N20000_scaled.parquet')  # data table for main parameters, scaled/non-dimensionalized


# ---- RF PARAMS ----
# Split siize
train_size = 0.2 # Small set for now
test_size  = 0.1

n_estimators = 100
max_depth    = 3
bootstrap    = True
oob_score    = True
n_jobs       = 2
min_samples_split = 2
# min_samples_leaf = 1
verbose = 1





# Load up data
monte_carlo_fixed_vars = mat2dict(monte_carlo_fixed_vars_file,'fixedVars')
monte_carlo_rand_vars  = pd.read_parquet(monte_carlo_rand_vars_file)
mc_df                  = pd.read_parquet(monte_carlo_data_file)
mc_df_scaled           = pd.read_parquet(monte_carlo_scaled_file)


# Check data overview
print('---> Fixed simulation input:\n\t')
pprint.pprint(monte_carlo_fixed_vars)
print('\n---> Randomized simulation input:\n\t', monte_carlo_rand_vars)
# monte_carlo_rand_vars.describe()
print('\n---> I/O data table:')
mc_df.info()
print(mc_df.describe())


# Make a scaled data set to better highlight physical relationships
%%matplotlibinline
mc_df_scaled = mc_df.copy()

mc_df['n_total'] = mc_df['n_0'] + mc_df['n_ec']
mc_df['Ze_over_Rv']

# Make a few descriptive plots of the dataset
input_vars = monte_carlo_rand_vars['Variable']
output_vars = ['rC_over_Rv','qw0_over_Q','qwC_over_Q','qs0_over_Q','qsC_over_Q']

sns.set_theme("whitegrid")
sns.pairplot(mc_df_scaled, vars=output_vars, hue="clps_regime")

faafo


## Build Random Forest


# ---- Create feature inputs for random forest ----

# mc_df['hm'] = mc_df['hm'].fillna(0.) # Should do this before in post-processing...

# Get logQ
logQ = np.log10(mc_df['Q'])
logQ.name = 'logQ'

# Get total vapor series
n_total = mc_df['n_0'] + mc_df['n_ec']
n_total.name = 'n_v'

# Setup input/output variables - consider non-dimensionalizing, then normalizing
X = pd.concat([logQ, mc_df['Ze'], n_total], axis=1)
Y = mc_df[['hm', 'qs0', 'qsC', 'rC', 'qw0', 'qwC']]

# Train/Test split
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size = train_size, test_size = test_size, random_state=42)
X_train.shape, X_test.shape


# ---- Build classifier and train initial random forest ----
regressor_rf = RandomForestRegressor(n_estimators=n_estimators, 
                                     max_depth=max_depth,
                                     bootstrap=bootstrap, 
                                     oob_score=oob_score,
                                     n_jobs=n_jobs,
                                     min_samples_split=min_samples_split,
                                     random_state=0,
                                     verbose=verbose)


regressor_rf.fit(X,Y)

# Get scores and initial predictions
regressor_rf.oob_score_
predictions = regressor_rf.predict(X_test)
